---
title: "LLM 모델 api을 활용하여 텍스트 생성 및 함수 호출"
date: 2025-10-25 16:00:00 +0900
categories: [AI]
tags: [ai, gemini, genai]
---

## 개요

토이프로젝트에서 유저의 체형 정보를 가지고 어울리는 의상을 추천해주는 서비스에 LLM 모델을 활용해보았다.

의상 검색 기능에는 네이버 쇼핑 api를 연동했다.

## LLM 모델 비교

가장 유명한 LLM 모델인 ChatGPT, Claude, Gemini 중에 선택하기로 했다.

아무래도 토이프로젝트다 보니 큰 요금이 나가는 것은 원치 않아서 요금을 중점적으로 비교했다.

| 모델                    | 입력                                                                                                  | 캐싱된 입력                                                                                                                           | 출력                                                                         |
| ----------------------- | ----------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------- |
| GPT-5                   | US$1.250/100만 개 토큰                                                                                | US$0.125/100만 개 토큰                                                                                                                | US$10.000/100만 개 토큰                                                      |
| GPT-5 pro               | US$15.00/100만 개 토큰                                                                                | -                                                                                                                                     | US$120.00/100만 개 토큰                                                      |
| Claude Opus 4.1         | $15 / MTok                                                                                            | Write : $18.75 / MTok<br/>Read : $1.50 / MTok                                                                                         | $75 / MTok                                                                   |
| Claude Sonnet 4.5       | Prompts ≤ 200K tokens : $3 / MTok<br/>Prompts > 200K tokens : $6 / MTok                               | ≤ 200K tokens :<br/>Write : $3.75 / MTok<br/>Read : $0.30 / MTok<br/>> 200K tokens :<br/>Write : $7.50 / MTok<br/>Read : $0.60 / MTok | Prompts ≤ 200K tokens : $15 / MTok<br/>Prompts > 200K tokens : $22.50 / MTok |
| Haiku 4.5               | $1 / MTok                                                                                             | Write : $1.25 / MTok<br/>Read : $0.10 / MTok                                                                                          | $5 / MTok                                                                    |
| Gemini 2.5 Pro (무료)   | $0 / MTok<br/>분당 요청 수 (RPM) : 5<br/>분당 토큰 수 : 125,000<br/>일일 요청 수 : 100                | -                                                                                                                                     | $0                                                                           |
| Gemini 2.5 Flash (무료) | $0 / MTok<br/>분당 요청 수 (RPM) : 10<br/>분당 토큰 수 : 250,000명<br/>일일 요청 수 : 250             | -                                                                                                                                     | $0                                                                           |
| Gemini 2.5 Pro          | $1.25, 프롬프트가 200,000개 이하의 토큰인 경우<br/>$2.50, 프롬프트가 200,000개를 초과하는 토큰인 경우 | $0.125, 프롬프트 <= 200,000개 토큰<br/>$0.25, 프롬프트 > 200,000개 토큰<br/>시간당 1,000,000개 토큰당$4.50 (스토리지 가격)            | $10.00, 프롬프트 <= 200,000개 토큰<br/>$15.00, 프롬프트 > 200,000개          |
| Gemini 2.5 Flash        | $0.30 (텍스트 / 이미지 / 동영상)<br/>$1.00 (오디오)                                                   | $0.03 (텍스트/이미지/동영상)<br/>$0.1 (오디오)<br/>시간당 토큰 1,000,000개당$1.00 (스토리지 가격)                                     | $2.50                                                                        |

Gemini 2.5 무료 등급으로도 충분히 개발 테스트가 가능할 것 같아 Gemini 2.5 무료 등급으로 결정했다.

이제 Gemini 2.5 Pro와 Gemini 2.5 Flash 모델 중에 어떤 것을 사용할 지 비교해보자.

| 모델             | 설명                                                                                                                                                              |
| ---------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Gemini 2.5 Pro   | 코드, 수학, STEM의 복잡한 문제를 추론할 수 있을 뿐만 아니라 긴 컨텍스트를 사용하여 대규모 데이터 세트, 코드베이스, 문서를 분석할 수 있는 최첨단 사고 모델         |
| Gemini 2.5 Flash | 최고의 가격 대비 성능을 갖추었으며 다양한 기능을 제공하는 모델 2.5 Flash는 대규모 처리, 짧은 지연 시간, 사고력이 필요한 대량 작업, 에이전트 사용 사례에 가장 적합 |

내가 개발할 기능에서는 복잡한 추론 작업이 필요하지 않기 때문에 분당/일일 요청 수, 분당 토큰 수가 더 많고 속도가 빠른 Gemini 2.5 Flash 모델로 최종 선택하였다.

#### 참고 사이트

- [LLM API 비용 총정리 2025년 3월 정보 (ChatGPT, Claude, Gemini, Deepseek 등)](https://pagetosuccess.com/llm-api-%EB%B9%84%EC%9A%A9-%EC%B4%9D%EC%A0%95%EB%A6%AC-2025%EB%85%84-3%EC%9B%94-%EC%A0%95%EB%B3%B4-chatgpt-claude-gemini-deepseek-%EB%93%B1/)
- [OpenAI API 가격](https://openai.com/ko-KR/api/pricing/)
- [Claude Pricing](https://www.claude.com/pricing#api)
- [Gemini Developer API 가격 책정](https://ai.google.dev/gemini-api/docs/pricing?hl=ko&_gl=1*nbtow4*_up*MQ..*_ga*MTg1NTI0MjQ2OC4xNzYxMzc1NTU0*_ga_P1DBVKWT6V*czE3NjEzNzU1NTQkbzEkZzAkdDE3NjEzNzU1NTQkajYwJGwwJGgxMTQ2MDkxODc1)

## Gemini 2.5 사용하기

[Google AI Studio](https://aistudio.google.com/api-keys)에서 프로젝트 및 API 키를 생성하고,

프로젝트에 패키지를 설치해준다.

```js
npm install @google/genai
```

`new GoogleGenAI({})`로 ai 객체를 생성한다.

### 텍스트 출력하기

`ai.models.generateContent`에 model과 contents를 전달하여 호출하면 출력을 생성할 수 있다.

```
import { GoogleGenAI } from "@google/genai";

// The client gets the API key from the environment variable `GEMINI_API_KEY`.
const ai = new GoogleGenAI({});

async function main() {
  const response = await ai.models.generateContent({
    model: "gemini-2.5-flash",
    contents: "Explain how AI works in a few words", // 프롬프트
  });
  console.log(response.text);
}

main();
```

### 구조화된 출력

Gemini는 JSON 또는 enum 값을 구조화된 출력으로 생성할 수 있다.

```js
import { GoogleGenAI, Type } from "@google/genai";

const ai = new GoogleGenAI({});

async function main() {
  const response = await ai.models.generateContent({
    model: "gemini-2.5-flash",
    contents:
      "List a few popular cookie recipes, and include the amounts of ingredients.",
    config: {
      responseMimeType: "application/json",
      responseSchema: {
        type: Type.ARRAY,
        items: {
          type: Type.OBJECT,
          properties: {
            recipeName: {
              type: Type.STRING
            },
            ingredients: {
              type: Type.ARRAY,
              items: {
                type: Type.STRING
              }
            }
          },
          propertyOrdering: ["recipeName", "ingredients"]
        }
      }
    }
  });

  console.log(response.text);
}

main();

// 출력값 :
// [
//   {
//     "recipeName": "Chocolate Chip Cookies",
//     "ingredients": [
//       "1 cup (2 sticks) unsalted butter, softened",
//       "3/4 cup granulated sugar",
//       "3/4 cup packed brown sugar",
//       "1 teaspoon vanilla extract",
//       "2 large eggs",
//       "2 1/4 cups all-purpose flour",
//       "1 teaspoon baking soda",
//       "1 teaspoon salt",
//       "2 cups chocolate chips"
//     ]
//   },
//   ...
// ]
```

### Gemini 2.5를 사용한 사고

2.5 Flash 및 Pro 모델은 품질을 향상하기 위해 기본적으로 '사고'가 사용 설정되어 있어 실행하는 데 시간이 더 걸리고 토큰 사용량이 증가할 수 있다.

`thinkingBudget` 파라미터는 대답을 생성할 때 사용할 사고 토큰 수를 모델에 안내한다.

일반적으로 토큰 수가 많을수록 더 자세한 추론이 가능하므로 복잡한 작업을 처리할 수 있다.

지연 시간이 더 중요한 경우 `thinkingBudget`을 낮추거나 0으로 설정하여 사고를 사용 중지할 수 있다.

사고를 중지하면 복잡한 추론이나 검증 과정을 거치지 않고 빠르게 출력한다.

`thinkingBudget`을 -1로 설정하면 동적 사고가 사용 설정된다. 즉, 모델이 요청의 복잡성에 따라 예산을 조정한다.

```js
const response = await ai.models.generateContent({
  model: "gemini-2.5-flash",
  contents: "How does AI work?",
  config: {
    thinkingConfig: {
      thinkingBudget: 0 // Disables thinking
    }
  }
});
```

| 모델             | 기본 설정 (사고 예산이 설정되지 않음)         | 범위      | 생각하는 과정 사용 중지    | 동적 사고 사용 설정 |
| ---------------- | --------------------------------------------- | --------- | -------------------------- | ------------------- |
| Gemini 2.5 Pro   | 동적 사고: 모델이 사고 시점과 사고량을 결정함 | 128~32768 | 생각을 사용 중지할 수 없음 | thinkingBudget = -1 |
| Gemini 2.5 Flash | 동적 사고: 모델이 사고 시점과 사고량을 결정함 | 0~24576   | thinkingBudget = 0         | thinkingBudget = -1 |

사실 확인이나 복잡한 추론이 필요하지 않은 간단한 요청은 사고를 중지하는 것이 효율적이고, 복잡한 수학 풀이나 코딩 등에는 사고 토큰을 최대로 사용하는 것이 좋다.

사고를 중지하는 것보다 동적 사고가 유연하게 출력할 것 같아서, 따로 세팅하지 않고 기본 설정(동적 사고)으로 두었다.

### 참고 사이트

[Gemini 생각](https://ai.google.dev/gemini-api/docs/thinking?hl=ko&_gl=1*em3d54*_up*MQ..*_ga*MTg1NTI0MjQ2OC4xNzYxMzc1NTU0*_ga_P1DBVKWT6V*czE3NjEzNzU1NTQkbzEkZzAkdDE3NjEzNzYwOTYkajYwJGwwJGgxMTQ2MDkxODc1)
